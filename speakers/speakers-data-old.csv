Name,"Position, University",Email,Photo,Title,Abstract,Bio,Page,HTML,Tex
Ali Ahari,"Scientific Researcher, Forschungszentrum Informatik",aliahary@gmail.com,ali-ahari.jpg,"Improving reliability, performance, and energy efficiency of STT-MRAM with dynamic write latency","High write latency and high write energy are the major challenges in Spin Transfer Torque Magnetic Random Access Memory (STT-MRAM) design. The write operation in STT-MRAM is of stochastic nature. Therefore, it requires a very long timing margin to maintain an acceptable level of reliability and yield. Traditionally, Error Correction Codes (ECCs) are used to reduce the timing margin in STT-MRAM. However, they impose high storage and latency overheads. In this talk, I present a low-cost architecture-level technique to significantly reduce the amount of required timing margin. This technique employs a handshaking protocol between the memory and its controller to dynamically determine the write latency at run-time. The simulation infrastructure comprehensively models the combined effect of process variation and stochastic write behavior at circuit-level and abstracts it to architecture-level. The simulation results show that this technique not only considerably reduces the write error rate but also improves the overall system performance on average by 15.4% compared to existing solutions.","Ali Ahari received his B.Sc. and M.Sc. degrees in Computer Engineering from Sharif University of Technology in 2011 and 2013, respectively. He has been a research assistant at the Chair of Dependable Nano computing at Karlsruhe Institute of Technology and also he has collaborated with the Chair of Embedded Security at Ruhr University as a visiting scholar. Since September 2015 he works as a scientific staff at the Department of Microelectronic System Design (SIM) of the FZI Forschungszetruminformatik in Karlsruhe, Germany.",ali-ahari.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/ali-ahari.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/ali-ahari.jpg' width='250px'></figure><h4>Ali Ahari</h4><p>Scientific Researcher, Forschungszentrum Informatik</p></a></div></div>","\newtalk{Ali Ahari}{aliahary@gmail.com}{ali-ahari.jpg}{Scientific Researcher, Forschungszentrum Informatik}{Ali Ahari received his B.Sc. and M.Sc. degrees in Computer Engineering from Sharif University of Technology in 2011 and 2013, respectively. He has been a research assistant at the Chair of Dependable Nano computing at Karlsruhe Institute of Technology and also he has collaborated with the Chair of Embedded Security at Ruhr University as a visiting scholar. Since September 2015 he works as a scientific staff at the Department of Microelectronic System Design (SIM) of the FZI Forschungszetruminformatik in Karlsruhe, Germany.}{Improving reliability, performance, and energy efficiency of STT-MRAM with dynamic write latency}{High write latency and high write energy are the major challenges in Spin Transfer Torque Magnetic Random Access Memory (STT-MRAM) design. The write operation in STT-MRAM is of stochastic nature. Therefore, it requires a very long timing margin to maintain an acceptable level of reliability and yield. Traditionally, Error Correction Codes (ECCs) are used to reduce the timing margin in STT-MRAM. However, they impose high storage and latency overheads. In this talk, I present a low-cost architecture-level technique to significantly reduce the amount of required timing margin. This technique employs a handshaking protocol between the memory and its controller to dynamically determine the write latency at run-time. The simulation infrastructure comprehensively models the combined effect of process variation and stochastic write behavior at circuit-level and abstracts it to architecture-level. The simulation results show that this technique not only considerably reduces the write error rate but also improves the overall system performance on average by 15.4% compared to existing solutions.}{ali-ahari.html}"
Ali Eslami,Google DeepMind,aeslami@google.com,ali-eslami.jpg,Beyond Supervised Deep Learning,"Deep learning has transformed the way in which we design machine learning systems. In this talk I will provide a brief overview of modern advances to the deep learning paradigm. Starting off with deep reinforcement learning: DQN (Nature, 2015) and A3C (CoRR, 2015), I will then motivate the role of generative modelling in the emerging research landscape and discuss several recent models, including PIxel CNNs (ICML, 2016), AIR (NIPS, 2016) and Conditional 2D->3D (NIPS, 2016).","Ali Eslami is a research scientist at Google DeepMind in London. Previously, he was a post-doctoral researcher at Microsoft Research in Cambridge. He did his PhD in the School of Informatics at the University of Edinburgh, during which he was also a visiting researcher in the Visual Geometry Group at the University of Oxford.",ali-eslami.html,<div class='col-md-3'><div class='speaker'><a href='speakers/ali-eslami.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/ali-eslami.jpg' width='250px'></figure><h4>Ali Eslami</h4><p>Google DeepMind</p></a></div></div>,"\newtalk{Ali Eslami}{aeslami@google.com}{ali-eslami.jpg}{Google DeepMind}{Ali Eslami is a research scientist at Google DeepMind in London. Previously, he was a post-doctoral researcher at Microsoft Research in Cambridge. He did his PhD in the School of Informatics at the University of Edinburgh, during which he was also a visiting researcher in the Visual Geometry Group at the University of Oxford.}{Beyond Supervised Deep Learning}{Deep learning has transformed the way in which we design machine learning systems. In this talk I will provide a brief overview of modern advances to the deep learning paradigm. Starting off with deep reinforcement learning: DQN (Nature, 2015) and A3C (CoRR, 2015), I will then motivate the role of generative modelling in the emerging research landscape and discuss several recent models, including PIxel CNNs (ICML, 2016), AIR (NIPS, 2016) and Conditional 2D->3D (NIPS, 2016).}{ali-eslami.html}"
Ali Mousavi,"PhD Candidate, Rice University",ali.mousavi@rice.edu,ali-mousavi.jpg,Deep Learning Approaches to Structured Signal Recovery,"The promise of compressive sensing (CS) has been offset by two significant challenges.  
First, real-world data is not exactly sparse in a fixed basis. Second, current high-performance recovery algorithms are slow to converge, which limits CS to either non-real-time applications or scenarios where massive back-end computing is available. We attack both of these challenges head-on by developing new signal recovery frameworks using deep learning techniques.","Ali Mousavi is currently pursuing the Ph.D. degree in the Department of Electrical and Computer Engineering at Rice University under supervision of Richard Baraniuk. He received B.Sc. degrees in electrical engineering from Sharif University of Technology in 2011. He received M.Sc. degree in electrical and computer engineering from Rice University in 2014. During summer 2010, he was a visiting researcher in laboratory of information and communication systems in École Polytechnique Fédérale de Lausanne under supervision of Suhas Diggavi. His research interests include machine learning and statistical signal processing, with a current emphasis on applications of data science in signal processing. Mr. Mousavi has been awarded Rice University George R. Brown School of Engineering Fellowship, Ken Kennedy Institute Schlumberger Graduate Fellowship, and Society of Iranian-American Women for Education Fellowship.",ali-mousavi.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/ali-mousavi.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/ali-mousavi.jpg' width='250px'></figure><h4>Ali Mousavi</h4><p>PhD Candidate, Rice University</p></a></div></div>","\newtalk{Ali Mousavi}{ali.mousavi@rice.edu}{ali-mousavi.jpg}{PhD Candidate, Rice University}{Ali Eslami is a research scientist at Google DeepMind in London. Previously, he was a post-doctoral researcher at Microsoft Research in Cambridge. He did his PhD in the School of Informatics at the University of Edinburgh, during which he was also a visiting researcher in the Visual Geometry Group at the University of Oxford.}{Beyond Supervised Deep Learning}{Deep learning has transformed the way in which we design machine learning systems. In this talk I will provide a brief overview of modern advances to the deep learning paradigm. Starting off with deep reinforcement learning: DQN (Nature, 2015) and A3C (CoRR, 2015), I will then motivate the role of generative modelling in the emerging research landscape and discuss several recent models, including PIxel CNNs (ICML, 2016), AIR (NIPS, 2016) and Conditional 2D->3D (NIPS, 2016).}{ali-mousavi.html}"
Ali Sharifi Zarchi,"Research Associate, Colorado State University, Fort Collins",asharifiz@gmail.com,ali-sharifi-zarchi.jpg,Using Deep Neural Networks to Understand the Cell Identity by Expression Fingerprints,"Understanding the cell identity is a critically important task in many biomedical areas, such as regenerative medicine and cancer research. The expression patterns of some marker genes have been used to assign the cells to a limited number of cell types. The limitations are unknown markers to accurately characterize many cell types, and the expression of markers in more than one cell type. A possible answer is using the whole-genome gene expression profiles (GEPs), but it has been computationally challenging to decide which genes can more accurately characterize the cell identity. Classical machine learning approaches, such as simple classification or clustering algorithms, have been applied for this problem as well as many other biological problems. Many aspects of biology, however, are much more sophisticated than can be modelled accurately using the simple approaches. During the past few years the deep learning methods have provided promising results in learning different patterns in games, images and video, etc. Their application in biology and health, however, has been limited. Here we analyzed a massive number of gene and miRNA expression profiles, measured by both Microarray and Next Generation Sequencing (NGS) platforms, to learn the more sphisticated biological properties of the data. After analyzing different architectures, we identified a specific artchitecture of the deep autoencoders that can compress the whole gene expression profiles into a small gene expression fingerprint (GEF) consisting of as few as 30 numeric values, that can reproduce the expression values of tens of thousands of genes with an accuracy comparable to technical replictes of the same experiment. We show that the scalars of the GEFs represent different biological pathways or processes, which are learned in an unsupervised approach. Furthermore, the cell identity can be inferred from the GEFs at very high accuracy, comparable to the state-of-the-art tools that work on the whole GEP.","Ali is a gold medal winner of the International Olympiad in Informatics (IOI), a graduate of B.Sc. and M.Sc. of Computer Engineering from Sharif Univ. of Tech. and Ph.D. of Bioinformatics from University of Tehran, a prior research fellow at Max Planck Institute for Molecular Biomedicine, and a prior Postdoc of Bioinformatics at Chitsaz Lab, Colorado State University. He is currently an associate of Bioinformatics in Colorado State University, an invited instructor at Computer Engineering department of Sharif Univ. of Tech., the head of Bioinformatics lab in Royan Institute for Stem Cell Biology and Technology, and most importantly a husband and father of two.",ali-sharifi-zarchi.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/ali-sharifi-zarchi.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/ali-sharifi-zarchi.jpg' width='250px'></figure><h4>Ali Sharifi Zarchi</h4><p>Research Associate, Colorado State University, Fort Collins</p></a></div></div>","\newtalk{Ali Sharifi Zarchi}{asharifiz@gmail.com}{ali-sharifi-zarchi.jpg}{Research Associate, Colorado State University, Fort Collins}{Ali is a gold medal winner of the International Olympiad in Informatics (IOI), a graduate of B.Sc. and M.Sc. of Computer Engineering from Sharif Univ. of Tech. and Ph.D. of Bioinformatics from University of Tehran, a prior research fellow at Max Planck Institute for Molecular Biomedicine, and a prior Postdoc of Bioinformatics at Chitsaz Lab, Colorado State University. He is currently an associate of Bioinformatics in Colorado State University, an invited instructor at Computer Engineering department of Sharif Univ. of Tech., the head of Bioinformatics lab in Royan Institute for Stem Cell Biology and Technology, and most importantly a husband and father of two.}{Using Deep Neural Networks to Understand the Cell Identity by Expression Fingerprints}{Understanding the cell identity is a critically important task in many biomedical areas, such as regenerative medicine and cancer research. The expression patterns of some marker genes have been used to assign the cells to a limited number of cell types. The limitations are unknown markers to accurately characterize many cell types, and the expression of markers in more than one cell type. A possible answer is using the whole-genome gene expression profiles (GEPs), but it has been computationally challenging to decide which genes can more accurately characterize the cell identity. Classical machine learning approaches, such as simple classification or clustering algorithms, have been applied for this problem as well as many other biological problems. Many aspects of biology, however, are much more sophisticated than can be modelled accurately using the simple approaches. During the past few years the deep learning methods have provided promising results in learning different patterns in games, images and video, etc. Their application in biology and health, however, has been limited. Here we analyzed a massive number of gene and miRNA expression profiles, measured by both Microarray and Next Generation Sequencing (NGS) platforms, to learn the more sphisticated biological properties of the data. After analyzing different architectures, we identified a specific artchitecture of the deep autoencoders that can compress the whole gene expression profiles into a small gene expression fingerprint (GEF) consisting of as few as 30 numeric values, that can reproduce the expression values of tens of thousands of genes with an accuracy comparable to technical replictes of the same experiment. We show that the scalars of the GEFs represent different biological pathways or processes, which are learned in an unsupervised approach. Furthermore, the cell identity can be inferred from the GEFs at very high accuracy, comparable to the state-of-the-art tools that work on the whole GEP.}{ali-sharifi-zarchi.html}"
Amin Sadeghi,"PhD, University of Illinois, Urbana-Champaign",,amin-sadeghi.jpg,Extracting Sound from Silent Video,"When sound waves propagate in air, they cause small vibrations when they hit objects. It has been shown that sound waves can be extracted by measuring these small vibrations in a video. In a recent work, we show that certain pixels in a video can record sound similar to a microphone. By studying local vibrations in detail, we isolate locations with higher sound quality and significantly improve sound quality. We also estimate incoming sound direction for the first time by measuring the delay between local sound readings. Finally, we reach real-time performance in 20KHz video by limiting computation to only a few localities.","Mohammad Amin Sadeghi completed his PhD at the University of Illinois at Urbana-Champaign. His research in Computer Vision and Machine Learning has been cited over 600 times. He has received the best student paper award at CVPR, which is the highest ranking conference in computer vision. He has recently started as a faculty member at the university of Tehran.",amin-sadeghi.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/amin-sadeghi.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/amin-sadeghi.jpg' width='250px'></figure><h4>Amin Sadeghi</h4><p>PhD, University of Illinois, Urbana-Champaign</p></a></div></div>","\newtalk{Amin Sadeghi}{}{amin-sadeghi.jpg}{PhD, University of Illinois, Urbana-Champaign}{-}{Advancements and challenges in quantum computers and quantum networks}{Over the past few decades, from a long standing effort by generations of scientist trying to understand the fundamentals of quantum mechanics, new concepts has emerged which is known as quantum computers and quantum networks. These platforms take advantage of parallel interaction between quantum two level systems – known as quantum bits (qbit) – in order to deliver efficient and novel techniques for some of the computational tasks that is either impossible or extremely difficult to solve via classical computers. This opens a new era in computer science not only to extend our computational capabilities but also paves the way for an unexplored regime that previously was not accessible with classical computers. On the other hand, quantum laws can be used in secure communication. Over the past years, scientist introduced several communication protocols that are impossible to hack and its security is guaranteed by the fundamental laws of quantum mechanics. These mostly theoretical achievements has raised interest among many researchers around the world in order to realize the quantum computers and quantum communication. In this talk we will review some of the basics of quantum computers and quantum communication protocol and their advantages compare to classical computers and finally discuss the experimental challenges in creating these platforms. In this talk, we start by reviewing some basics about quantum mechanics, especially how quantum computers and quantum communication protocols are deeply connected to the concepts of entanglement and act of measurements in quantum mechanics. Then we briefly review the building blocks of quantum computers, known as quantum gates and the basic working principles of quantum computers. In the next step we discuss how quantum computers can solve some class of computational tasks in a more efficient way by taking advantages of their large Hilbert space and briefly introduce the Shor’s algorithm as an example. Next we review some of the experimental challenges in building the quantum computers and especially discuss how temperature pose a fundamental limit on quantum computers via the process of thermal decoherence. Next we briefly introduce several experimental platforms such as superconducting circuits, atom trapping and etc. which was studied by researchers in recent years. Finally we will see in more details how nano-mechanical oscillator can play a role as a novel platform for some applications in quantum computer domain such as quantum memories and quantum transducers.}{amin-sadeghi.html}"
Amir Hossein Ghadimi,"PhD, École Polytechnique Fédérale de Lausanne",amir.ghadimi@epfl.ch,amir-hosein-ghadimi.jpg,Advancements and challenges in quantum computers and quantum networks,"Over the past few decades, from a long standing effort by generations of scientist trying to understand the fundamentals of quantum mechanics, new concepts has emerged which is known as quantum computers and quantum networks. These platforms take advantage of parallel interaction between quantum two level systems – known as quantum bits (qbit) – in order to deliver efficient and novel techniques for some of the computational tasks that is either impossible or extremely difficult to solve via classical computers. This opens a new era in computer science not only to extend our computational capabilities but also paves the way for an unexplored regime that previously was not accessible with classical computers. On the other hand, quantum laws can be used in secure communication. Over the past years, scientist introduced several communication protocols that are impossible to hack and its security is guaranteed by the fundamental laws of quantum mechanics. These mostly theoretical achievements has raised interest among many researchers around the world in order to realize the quantum computers and quantum communication. In this talk we will review some of the basics of quantum computers and quantum communication protocol and their advantages compare to classical computers and finally discuss the experimental challenges in creating these platforms. In this talk, we start by reviewing some basics about quantum mechanics, especially how quantum computers and quantum communication protocols are deeply connected to the concepts of entanglement and act of measurements in quantum mechanics. Then we briefly review the building blocks of quantum computers, known as quantum gates and the basic working principles of quantum computers. In the next step we discuss how quantum computers can solve some class of computational tasks in a more efficient way by taking advantages of their large Hilbert space and briefly introduce the Shor’s algorithm as an example. Next we review some of the experimental challenges in building the quantum computers and especially discuss how temperature pose a fundamental limit on quantum computers via the process of thermal decoherence. Next we briefly introduce several experimental platforms such as superconducting circuits, atom trapping and etc. which was studied by researchers in recent years. Finally we will see in more details how nano-mechanical oscillator can play a role as a novel platform for some applications in quantum computer domain such as quantum memories and quantum transducers.",-,amir-hossein-ghadimi.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/amir-hossein-ghadimi.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/amir-hosein-ghadimi.jpg' width='250px'></figure><h4>Amir Hossein Ghadimi</h4><p>PhD, École Polytechnique Fédérale de Lausanne</p></a></div></div>","\newtalk{Amir Hossein Ghadimi}{amir.ghadimi@epfl.ch}{amir-hosein-ghadimi.jpg}{PhD, École Polytechnique Fédérale de Lausanne}{-}{Advancements and challenges in quantum computers and quantum networks}{Over the past few decades, from a long standing effort by generations of scientist trying to understand the fundamentals of quantum mechanics, new concepts has emerged which is known as quantum computers and quantum networks. These platforms take advantage of parallel interaction between quantum two level systems – known as quantum bits (qbit) – in order to deliver efficient and novel techniques for some of the computational tasks that is either impossible or extremely difficult to solve via classical computers. This opens a new era in computer science not only to extend our computational capabilities but also paves the way for an unexplored regime that previously was not accessible with classical computers. On the other hand, quantum laws can be used in secure communication. Over the past years, scientist introduced several communication protocols that are impossible to hack and its security is guaranteed by the fundamental laws of quantum mechanics. These mostly theoretical achievements has raised interest among many researchers around the world in order to realize the quantum computers and quantum communication. In this talk we will review some of the basics of quantum computers and quantum communication protocol and their advantages compare to classical computers and finally discuss the experimental challenges in creating these platforms. In this talk, we start by reviewing some basics about quantum mechanics, especially how quantum computers and quantum communication protocols are deeply connected to the concepts of entanglement and act of measurements in quantum mechanics. Then we briefly review the building blocks of quantum computers, known as quantum gates and the basic working principles of quantum computers. In the next step we discuss how quantum computers can solve some class of computational tasks in a more efficient way by taking advantages of their large Hilbert space and briefly introduce the Shor’s algorithm as an example. Next we review some of the experimental challenges in building the quantum computers and especially discuss how temperature pose a fundamental limit on quantum computers via the process of thermal decoherence. Next we briefly introduce several experimental platforms such as superconducting circuits, atom trapping and etc. which was studied by researchers in recent years. Finally we will see in more details how nano-mechanical oscillator can play a role as a novel platform for some applications in quantum computer domain such as quantum memories and quantum transducers.}{amir-hossein-ghadimi.html}"
Amir Shaikhha,"PhD, École Polytechnique Fédérale de Lausanne",amir.shaikhha@epfl.ch,armi-shaikhha.jpg,How to Architect a Query Compiler,"In this talk we study architecting query compilers. The state of the art in query compiler construction is lagging behind that in the compilers field. We attempt to remedy this by exploring the key causes of technical challenges in need of well founded solutions, and by gathering the most relevant ideas and approaches from the PL and compilers communities for easy digestion by database researchers. All query compilers known to us are more or less monolithic template expanders that do the bulk of the compilation task in one large leap. Such systems are hard to build and maintain. We propose to use a stack of multiple DSLs on different levels of abstraction with lowering in multiple steps to make query compilers easier to build and extend, ultimately allowing us to create more convincing and sustainable compiler-based data management systems. We attempt to derive our advice for creating such DSL stacks from widely acceptable principles. We have also re-created a well-known query compiler following these ideas and report on this effort.","Amir Shaikhha is a 4th year Ph.D. student at EPFL. His research aims to build efficient data analytics systems using high-level languages. More specifically, he is interested in using compilation techniques for generating efficient low-level code (e.g. C code) from the high-level specification (e.g. Scala code) of performance-critical systems (e.g. database systems). He received his M.Sc. from EPFL and B.S. from Sharif University of Technology. ​",amir-shaikhha.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/amir-shaikhha.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/armi-shaikhha.jpg' width='250px'></figure><h4>Amir Shaikhha</h4><p>PhD, École Polytechnique Fédérale de Lausanne</p></a></div></div>","\newtalk{Amir Shaikhha}{amir.shaikhha@epfl.ch}{armi-shaikhha.jpg}{PhD, École Polytechnique Fédérale de Lausanne}{Amir Shaikhha is a 4th year Ph.D. student at EPFL. His research aims to build efficient data analytics systems using high-level languages. More specifically, he is interested in using compilation techniques for generating efficient low-level code (e.g. C code) from the high-level specification (e.g. Scala code) of performance-critical systems (e.g. database systems). He received his M.Sc. from EPFL and B.S. from Sharif University of Technology. ​}{How to Architect a Query Compiler}{In this talk we study architecting query compilers. The state of the art in query compiler construction is lagging behind that in the compilers field. We attempt to remedy this by exploring the key causes of technical challenges in need of well founded solutions, and by gathering the most relevant ideas and approaches from the PL and compilers communities for easy digestion by database researchers. All query compilers known to us are more or less monolithic template expanders that do the bulk of the compilation task in one large leap. Such systems are hard to build and maintain. We propose to use a stack of multiple DSLs on different levels of abstraction with lowering in multiple steps to make query compilers easier to build and extend, ultimately allowing us to create more convincing and sustainable compiler-based data management systems. We attempt to derive our advice for creating such DSL stacks from widely acceptable principles. We have also re-created a well-known query compiler following these ideas and report on this effort.}{amir-shaikhha.html}"
Amir Zandieh,"PhD, École Polytechnique Fédérale de Lausanne",amir.zandieh@epfl.ch,armi-zandieh.jpg,Nearly optimal Sparse FF,"The problem of approximately computing the k dominant Fourier coefficients of a vector quickly and using few samples in time domain is known as the Sparse Fourier Transform (Sparse FFT) problem. A long line of work on Sparse FFT has resulted in algorithms with O(k log⁡n  log⁡〖(n/k)〗) runtime and O(k log⁡n) sample complexity [Hassanieh et al’STOC’12]. The mentioned result is non-adaptive, and is essentially the best possible under the sparsity assumption alone: It is known that even adaptive algorithms must use Ω((k log⁡n)/log⁡log⁡n  ) samples [Hassanieh et al, STOC’12]. 
We consider the problem of computing the k-sparse approximation to the discrete Fourier transform of an n-dimensional signal. The following are presented in [Hassanieh et al’STOC’12]:
• An O(k log⁡n)-time randomized algorithm for the case where the input signal has at most k non-zero Fourier coefficients, and 
• An O(k log⁡n  log⁡〖(n/k)〗)-time randomized algorithm for general input signals. 
Both algorithms achieve o(n log⁡n) time, and thus improve over the Fast Fourier Transform, for any k=o(n). They are the first known algorithms that satisfy this property. Also, if one assumes that the Fast Fourier Transform is optimal, the algorithm for the exactly k-sparse case is optimal for any k=n^(Ω(1)).
",Amir Zandieh is a PhD student at EPFL. He works on randomized approximation algorithms and is advised by prof. Michael Kapralov. His research interests are on Sparse recovery as well as sketching and Fourier sampling.,amir-zandieh.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/amir-zandieh.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/armi-zandieh.jpg' width='250px'></figure><h4>Amir Zandieh</h4><p>PhD, École Polytechnique Fédérale de Lausanne</p></a></div></div>","\newtalk{Amir Zandieh}{amir.zandieh@epfl.ch}{armi-zandieh.jpg}{PhD, École Polytechnique Fédérale de Lausanne}{Amir Zandieh is a PhD student at EPFL. He works on randomized approximation algorithms and is advised by prof. Michael Kapralov. His research interests are on Sparse recovery as well as sketching and Fourier sampling.}{Nearly optimal Sparse FF}{The problem of approximately computing the k dominant Fourier coefficients of a vector quickly and using few samples in time domain is known as the Sparse Fourier Transform (Sparse FFT) problem. A long line of work on Sparse FFT has resulted in algorithms with O(k log⁡n  log⁡〖(n/k)〗) runtime and O(k log⁡n) sample complexity [Hassanieh et al’STOC’12]. The mentioned result is non-adaptive, and is essentially the best possible under the sparsity assumption alone: It is known that even adaptive algorithms must use Ω((k log⁡n)/log⁡log⁡n  ) samples [Hassanieh et al, STOC’12]. 
We consider the problem of computing the k-sparse approximation to the discrete Fourier transform of an n-dimensional signal. The following are presented in [Hassanieh et al’STOC’12]:
• An O(k log⁡n)-time randomized algorithm for the case where the input signal has at most k non-zero Fourier coefficients, and 
• An O(k log⁡n  log⁡〖(n/k)〗)-time randomized algorithm for general input signals. 
Both algorithms achieve o(n log⁡n) time, and thus improve over the Fast Fourier Transform, for any k=o(n). They are the first known algorithms that satisfy this property. Also, if one assumes that the Fast Fourier Transform is optimal, the algorithm for the exactly k-sparse case is optimal for any k=n^(Ω(1)).
}{amir-zandieh.html}"
Ashkan Norouzi Fard,"PhD, École Polytechnique Fédérale de Lausanne",ashkan.norouzifard@epfl.ch,ashkan-norouzi-fard.jpg,Practical vs Theoretical Computer Science,"In this talk we focus on the Travelling Salesman Problem in two different settings. First we focus on the theoretical results for this problem, then we continue by introducing one on the applications of this problem in real world. The application that we discuss is “over-night bike rebalancing”. We present the state of the art algorithm that Citibike, the biggest bike sharing company in US, is currently using.","Ashkan Norouzi-Fard received his B.Sc. in Computer Engineering-Software at Sharif University of Technology (2013). He is currently a Ph.D. student at Ecole Polytechnique Federal de Lausanne (EPFL), under the supervision of Ola Svensson. His research focuses on Approximation Algorithms and their applications in real world.",ashkan-norouzi-fard.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/ashkan-norouzi-fard.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/ashkan-norouzi-fard.jpg' width='250px'></figure><h4>Ashkan Norouzi Fard</h4><p>PhD, École Polytechnique Fédérale de Lausanne</p></a></div></div>","\newtalk{Ashkan Norouzi Fard}{ashkan.norouzifard@epfl.ch}{ashkan-norouzi-fard.jpg}{PhD, École Polytechnique Fédérale de Lausanne}{Ashkan Norouzi-Fard received his B.Sc. in Computer Engineering-Software at Sharif University of Technology (2013). He is currently a Ph.D. student at Ecole Polytechnique Federal de Lausanne (EPFL), under the supervision of Ola Svensson. His research focuses on Approximation Algorithms and their applications in real world.}{Practical vs Theoretical Computer Science}{In this talk we focus on the Travelling Salesman Problem in two different settings. First we focus on the theoretical results for this problem, then we continue by introducing one on the applications of this problem in real world. The application that we discuss is “over-night bike rebalancing”. We present the state of the art algorithm that Citibike, the biggest bike sharing company in US, is currently using.}{ashkan-norouzi-fard.html}"
Banafsheh Behzad,"Assistant Professor, California State University, Long Beach",banafsheh.behzad@csulb.edu,banafsheh-behzad.jpg,The Application of Game Theory in Analyzing Public Health Issues,"This research introduces a variation of the Bertrand price game, in which production capacity constraints and product differentiation are incorporated.  Equilibrium prices in both pure strategy and mixed strategy are sought. Complete characterization of mixed strategy equilibrium in such games is introduced. The game is applied to identify the equilibrium prices of the vaccines sold in the US pediatric vaccine market. The results provide insights for pediatric healthcare community, including federal government officials and vaccine manufacturers who are seeking effective pricing strategies.","Dr. Banafsheh Behzad is an Assistant Professor of Information Systems in the College of Business Administration, California State University, Long Beach. She holds a Ph.D. in Industrial Engineering from University of Illinois at Urbana-Champaign and a B.Sc. in Industrial Engineering from Sharif University of Technology. Her research interests include game theory and its application in public health and social networks.",banafsheh-behzad.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/banafsheh-behzad.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/banafsheh-behzad.jpg' width='250px'></figure><h4>Banafsheh Behzad</h4><p>Assistant Professor, California State University, Long Beach</p></a></div></div>","\newtalk{Banafsheh Behzad}{banafsheh.behzad@csulb.edu}{banafsheh-behzad.jpg}{Assistant Professor, California State University, Long Beach}{Dr. Banafsheh Behzad is an Assistant Professor of Information Systems in the College of Business Administration, California State University, Long Beach. She holds a Ph.D. in Industrial Engineering from University of Illinois at Urbana-Champaign and a B.Sc. in Industrial Engineering from Sharif University of Technology. Her research interests include game theory and its application in public health and social networks.}{The Application of Game Theory in Analyzing Public Health Issues}{This research introduces a variation of the Bertrand price game, in which production capacity constraints and product differentiation are incorporated.  Equilibrium prices in both pure strategy and mixed strategy are sought. Complete characterization of mixed strategy equilibrium in such games is introduced. The game is applied to identify the equilibrium prices of the vaccines sold in the US pediatric vaccine market. The results provide insights for pediatric healthcare community, including federal government officials and vaccine manufacturers who are seeking effective pricing strategies.}{banafsheh-behzad.html}"
Ehsan Asgari,"PhD Candidate, University of California, Berkeley",asgari@berkeley.edu,ehsan-asgari.jpg,Continuous Distributed Representation of Biological Sequences and Their Applications in Bioinformatics,"Biophysical and biochemical principles govern biological sequences (e.g., DNA, RNA, and protein sequences) similar to the way grammar of a natural language determines the structure of clauses and sentences. This analogy motivates ‘life language processing’, i.e. treating biological sequences as the output of a certain language and adopt/develop language processing methods to preform analyses and predictions in that language. We propose two specific aims for life language processing: (1) Developing computational linguistics representation learning for biological sequences: the large gap between the number of known sequences (raw data) versus the number of known functions/structures associated with these sequences (meta-data), encourage us to develop methods that can obtain prior knowledge from the existing sequences. Continuous vector representations of words known as word vectors have recently become popular in natural language processing (NLP) as an efficient unsupervised approach to represent semantic/syntactic units of text helping in the downstream NLP tasks (e.g., machine translation, part-of-speech tagging, information retrieval, etc.). In this work, we propose distributed vector representations of biological sequence segments (n-grams), called bio-vectors, using skip-gram neural network. We propose intrinsic evaluation of bio-vectors by measuring the continuity of the underlying biophysical and biochemical properties (e.g., average mass, hydrophobicity, charge, and etc.). In addition to intrinsic evaluations, for the purpose of extrinsic evaluations, we have employed this representation in classification of 324018 protein sequences belonging to 7027 protein families, where an average family classification accuracy of 93%±0.06% was obtained. In addition, incorporation of bio-vector representation versus one-hot vector features in Maxmargin Markov Network (M3Net) for intron-exon prediction and domain identification tasks could improve the sequence labeling accuracy from 73.84% to 74.99% and from 82.4% to 89.8%, respectively. (2) Performing computational linguistics comparison of genomic language variations: the purpose of this aim is to quantify the distances between syntactic and semantic features of two genomic language variations, with various applications in comparative genomics. Training model of bio-vectors is analogous to neural probabilistic language modeling. Hence, such representations can characterize sequences in terms of underlying biochemical and biophysical patterns. This makes the network of n-grams in this space an indirect representation of the underlying language model. Considering this fact, we propose a new quantitative measure of distance between genomic language variations based on the divergence between networks of ngrams in different genetic variations, called word embedding language divergence. We perform language comparison for the coding regions in the genomes of 12 different organisms (4 plants, 6 animals, and two human subjects). Our results confirm a significant high-level difference in the genetic language model of humans/animals versus plants. The proposed method is a step toward defining a new quantitative measure of similarity between genomic languages, with applications in characterization/classification of sequences of interest.","Ehsaneddin Asgari is a PhD candidate at University of California, Berkeley. His PhD research explores the development of deep learning, specifically deep language processing methods for performing analysis and predictions on genomics and metagenomics sequences. His research interests are in the areas of Bioinformatics and Natural Language Processing. He is a former researcher at Deep Language Processing group at LMU, Genesis group at MIT Computer Science and Artificial Intelligence Laboratory, Neuroscience Statistics Lab at MIT Brain and Cognitive Science Department, ABB Corporate Research, Audiovisual Communications Lab at EPFL, ADSC of UIUC, and Digital Media Lab. He received his M.Sc. degrees from UC Berkeley and EPFL and his B.Sc. from Sharif University of Technology in Computer Engineering.",ehsan-asgari.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/ehsan-asgari.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/ehsan-asgari.jpg' width='250px'></figure><h4>Ehsan Asgari</h4><p>PhD Candidate, University of California, Berkeley</p></a></div></div>","\newtalk{Ehsan Asgari}{asgari@berkeley.edu}{ehsan-asgari.jpg}{PhD Candidate, University of California, Berkeley}{Ehsaneddin Asgari is a PhD candidate at University of California, Berkeley. His PhD research explores the development of deep learning, specifically deep language processing methods for performing analysis and predictions on genomics and metagenomics sequences. His research interests are in the areas of Bioinformatics and Natural Language Processing. He is a former researcher at Deep Language Processing group at LMU, Genesis group at MIT Computer Science and Artificial Intelligence Laboratory, Neuroscience Statistics Lab at MIT Brain and Cognitive Science Department, ABB Corporate Research, Audiovisual Communications Lab at EPFL, ADSC of UIUC, and Digital Media Lab. He received his M.Sc. degrees from UC Berkeley and EPFL and his B.Sc. from Sharif University of Technology in Computer Engineering.}{Continuous Distributed Representation of Biological Sequences and Their Applications in Bioinformatics}{Biophysical and biochemical principles govern biological sequences (e.g., DNA, RNA, and protein sequences) similar to the way grammar of a natural language determines the structure of clauses and sentences. This analogy motivates ‘life language processing’, i.e. treating biological sequences as the output of a certain language and adopt/develop language processing methods to preform analyses and predictions in that language. We propose two specific aims for life language processing: (1) Developing computational linguistics representation learning for biological sequences: the large gap between the number of known sequences (raw data) versus the number of known functions/structures associated with these sequences (meta-data), encourage us to develop methods that can obtain prior knowledge from the existing sequences. Continuous vector representations of words known as word vectors have recently become popular in natural language processing (NLP) as an efficient unsupervised approach to represent semantic/syntactic units of text helping in the downstream NLP tasks (e.g., machine translation, part-of-speech tagging, information retrieval, etc.). In this work, we propose distributed vector representations of biological sequence segments (n-grams), called bio-vectors, using skip-gram neural network. We propose intrinsic evaluation of bio-vectors by measuring the continuity of the underlying biophysical and biochemical properties (e.g., average mass, hydrophobicity, charge, and etc.). In addition to intrinsic evaluations, for the purpose of extrinsic evaluations, we have employed this representation in classification of 324018 protein sequences belonging to 7027 protein families, where an average family classification accuracy of 93%±0.06% was obtained. In addition, incorporation of bio-vector representation versus one-hot vector features in Maxmargin Markov Network (M3Net) for intron-exon prediction and domain identification tasks could improve the sequence labeling accuracy from 73.84% to 74.99% and from 82.4% to 89.8%, respectively. (2) Performing computational linguistics comparison of genomic language variations: the purpose of this aim is to quantify the distances between syntactic and semantic features of two genomic language variations, with various applications in comparative genomics. Training model of bio-vectors is analogous to neural probabilistic language modeling. Hence, such representations can characterize sequences in terms of underlying biochemical and biophysical patterns. This makes the network of n-grams in this space an indirect representation of the underlying language model. Considering this fact, we propose a new quantitative measure of distance between genomic language variations based on the divergence between networks of ngrams in different genetic variations, called word embedding language divergence. We perform language comparison for the coding regions in the genomes of 12 different organisms (4 plants, 6 animals, and two human subjects). Our results confirm a significant high-level difference in the genetic language model of humans/animals versus plants. The proposed method is a step toward defining a new quantitative measure of similarity between genomic languages, with applications in characterization/classification of sequences of interest.}{ehsan-asgari.html}"
Farnoud Salehi,"PhD, École Polytechnique Fédérale de Lausanne",farnood.salehi@epfl.ch,farnoud-salehi.jpg,Applications of Matrix Factorization in signal processing,"Matrix factorization-that is, representing a signal  by suitable basis functions is widely used in machine learning, image denoising, signal processing and neuroscience.  This problem usually comes with two main assumptions about the signal: the signal’s components either are independent or sparse. More precisely, in the independent-component analysis (ICA), the signal considered is a mixture of some independent sources. Source separation is one example for ICA. In contrast, in the sparse component analysis (SCA), the signal is assumed to be a mixture of sparse sources. We present an overview of the ICA and SCA from the matrix factorization point of view.","I received my B.Sc. in Electrical Engineering from Sharif University of Technology in 2014. Now, I am working towards my PhD in the Laboratory of Communications and Applications under the supervision of Prof. Thiran and Dr. Celis. My research interest revolves around Machine Learning.  I am particularly interested in developing algorithms for fast Dictionary Learning and Multi-armed Bandits.",farnoud-salehi.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/farnoud-salehi.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/farnoud-salehi.jpg' width='250px'></figure><h4>Farnoud Salehi</h4><p>PhD, École Polytechnique Fédérale de Lausanne</p></a></div></div>","\newtalk{Farnoud Salehi}{farnood.salehi@epfl.ch}{farnoud-salehi.jpg}{PhD, École Polytechnique Fédérale de Lausanne}{I received my B.Sc. in Electrical Engineering from Sharif University of Technology in 2014. Now, I am working towards my PhD in the Laboratory of Communications and Applications under the supervision of Prof. Thiran and Dr. Celis. My research interest revolves around Machine Learning.  I am particularly interested in developing algorithms for fast Dictionary Learning and Multi-armed Bandits.}{Applications of Matrix Factorization in signal processing}{Matrix factorization-that is, representing a signal  by suitable basis functions is widely used in machine learning, image denoising, signal processing and neuroscience.  This problem usually comes with two main assumptions about the signal: the signal’s components either are independent or sparse. More precisely, in the independent-component analysis (ICA), the signal considered is a mixture of some independent sources. Source separation is one example for ICA. In contrast, in the sparse component analysis (SCA), the signal is assumed to be a mixture of sparse sources. We present an overview of the ICA and SCA from the matrix factorization point of view.}{farnoud-salehi.html}"
Hamid Mahini,"Researcher, University of Maryland",hamid.mahini@gmail.com,hamid-mahini.jpg,How to Influence People with Partial Incentives,"We study the power of fractional allocations of resources to maximize influence in a network. This work extends in a natural way the well-studied model by Kempe, Kleinberg, and Tardos (2003), where a designer selects a (small) seed set of nodes in a social network to influence directly, this influence cascades when other nodes reach certain thresholds of neighbor influence, and the goal is to maximize the final number of influenced nodes. Despite extensive study from both practical and theoretical viewpoints, this model limits the designer to a binary choice for each node, with no way to apply intermediate levels of influence. This model captures some settings precisely, e.g. exposure to an idea or pathogen, but it fails to capture very relevant concerns in others, for example, a manufacturer promoting a new product by distributing five """"20% off"""" coupons instead of giving away one free product. While fractional versions of problems tend to be easier to solve than integral versions, for influence maximization, we show that the two versions have essentially the same computational complexity. On the other hand, the two versions can have vastly different solutions: the added flexibility of fractional allocation can lead to significantly improved influence. Our main theoretical contribution is to show how to adapt the major positive results from the integral case to the fractional case. Specifically, Mossel and Roch (2006) used the submodularity of influence to obtain their integral results; we introduce a new notion of continuous submodularity, and use this to obtain matching fractional results. We conclude that we can achieve the same greedy (1−1/e−ϵ)-approximation for the fractional case as the integral case. In practice, we find that the fractional model performs substantially better than the integral model, according to simulations on real-world social network data.","Assistant professor, University of Tehran, 2016-now
CTO at TAP30, 2015-now
Research Scientist, Rocket Fuel Inc, San Francisco Bay Area, 2015
Postdoctoral Research, CS Department, University of Maryland, 2012-2014
PhD, Computer Engineering, Sharif University of Technology, 2006-2011",hamid-mahini.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/hamid-mahini.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/hamid-mahini.jpg' width='250px'></figure><h4>Hamid Mahini</h4><p>Researcher, University of Maryland</p></a></div></div>","\newtalk{Hamid Mahini}{hamid.mahini@gmail.com}{hamid-mahini.jpg}{Researcher, University of Maryland}{Assistant professor, University of Tehran, 2016-now
CTO at TAP30, 2015-now
Research Scientist, Rocket Fuel Inc, San Francisco Bay Area, 2015
Postdoctoral Research, CS Department, University of Maryland, 2012-2014
PhD, Computer Engineering, Sharif University of Technology, 2006-2011}{How to Influence People with Partial Incentives}{We study the power of fractional allocations of resources to maximize influence in a network. This work extends in a natural way the well-studied model by Kempe, Kleinberg, and Tardos (2003), where a designer selects a (small) seed set of nodes in a social network to influence directly, this influence cascades when other nodes reach certain thresholds of neighbor influence, and the goal is to maximize the final number of influenced nodes. Despite extensive study from both practical and theoretical viewpoints, this model limits the designer to a binary choice for each node, with no way to apply intermediate levels of influence. This model captures some settings precisely, e.g. exposure to an idea or pathogen, but it fails to capture very relevant concerns in others, for example, a manufacturer promoting a new product by distributing five """"20% off"""" coupons instead of giving away one free product. While fractional versions of problems tend to be easier to solve than integral versions, for influence maximization, we show that the two versions have essentially the same computational complexity. On the other hand, the two versions can have vastly different solutions: the added flexibility of fractional allocation can lead to significantly improved influence. Our main theoretical contribution is to show how to adapt the major positive results from the integral case to the fractional case. Specifically, Mossel and Roch (2006) used the submodularity of influence to obtain their integral results; we introduce a new notion of continuous submodularity, and use this to obtain matching fractional results. We conclude that we can achieve the same greedy (1−1/e−ϵ)-approximation for the fractional case as the integral case. In practice, we find that the fractional model performs substantially better than the integral model, according to simulations on real-world social network data.}{hamid-mahini.html}"
Hamid Nazerzadeh,"Associate Professor, University of Southern California",nazerzad@marshall.usc.edu,hamid-nazerzadeh.jpg,Real-Time Optimization of Personalized Assortments,"Motivated by the availability of real-time data on customer characteristics, we consider the problem of personalizing the assortment of products for each arriving customer. Using actual sales data from an online retailer, we demonstrate that personalization based on each customer’s location can lead to over 10% improvements in revenue compared to a policy that treats all customers the same. We propose a family of index-based policies that effectively coordinate the real-time assortment decisions with the backend supply chain constraints. We allow the demand process to be arbitrary and prove that our algorithms achieve an optimal competitive ratio. In addition, we show that our algorithms perform even better if the demand is known to be stationary. Our approach is also flexible and can be combined with existing methods in the literature, resulting in a hybrid algorithm that brings out the advantages of other methods while maintaining the worst-case performance guarantees","Hamid Nazerzadeh is an associate professor in the Data Sciences and Operations department at Marshall School of Business, and (by courtesy), Department of Computer Science, University of Southern California. He obtained his Ph.D. in Operations Research from Stanford University and his B.Sc. from Sharif University of Technology and has worked at Microsoft, Yahoo!, and Google research labs. His research focuses on mechanism design and optimization algorithms and their applications in operations and monetization of online markets. He is the recipient of Yahoo! Ph.D. Student Fellowship Award (2007), Honorable Mention in George Dantzig Dissertation Awards (2009), Google Faculty Research Award (2013), Marshall Dean's Award for Research Excellence (2014), and INFORMS Revenue Management and Pricing Section Prize (2014).",hamid-nazerzadeh.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/hamid-nazerzadeh.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/hamid-nazerzadeh.jpg' width='250px'></figure><h4>Hamid Nazerzadeh</h4><p>Associate Professor, University of Southern California</p></a></div></div>","\newtalk{Hamid Nazerzadeh}{nazerzad@marshall.usc.edu}{hamid-nazerzadeh.jpg}{Associate Professor, University of Southern California}{Hamid Nazerzadeh is an associate professor in the Data Sciences and Operations department at Marshall School of Business, and (by courtesy), Department of Computer Science, University of Southern California. He obtained his Ph.D. in Operations Research from Stanford University and his B.Sc. from Sharif University of Technology and has worked at Microsoft, Yahoo!, and Google research labs. His research focuses on mechanism design and optimization algorithms and their applications in operations and monetization of online markets. He is the recipient of Yahoo! Ph.D. Student Fellowship Award (2007), Honorable Mention in George Dantzig Dissertation Awards (2009), Google Faculty Research Award (2013), Marshall Dean's Award for Research Excellence (2014), and INFORMS Revenue Management and Pricing Section Prize (2014).}{Real-Time Optimization of Personalized Assortments}{Motivated by the availability of real-time data on customer characteristics, we consider the problem of personalizing the assortment of products for each arriving customer. Using actual sales data from an online retailer, we demonstrate that personalization based on each customer’s location can lead to over 10% improvements in revenue compared to a policy that treats all customers the same. We propose a family of index-based policies that effectively coordinate the real-time assortment decisions with the backend supply chain constraints. We allow the demand process to be arbitrary and prove that our algorithms achieve an optimal competitive ratio. In addition, we show that our algorithms perform even better if the demand is known to be stationary. Our approach is also flexible and can be combined with existing methods in the literature, resulting in a hybrid algorithm that brings out the advantages of other methods while maintaining the worst-case performance guarantees}{hamid-nazerzadeh.html}"
Hossein Akhlaghpour,,,hossein-akhlaghpour.jpg,How Deep Learning shapes the future of Bioinformatics,"In this talk we go over different aspects of Bioinformatics and show how Machine Learning and specifically Deep Learning will have such an impact that future Bioinformaticians are none but Computer Scientists specialized on Deep Learning.
We show how Google and Microsoft are the ones that not only lead bioinformatics but also can monopolize this industry.  What we call Bioinformatics today will be the blueprint of manufacturing of all kind of products from foods and drugs to batteries,  solar cells, industrial and construction materials. Such an explosion of applications are not possible without turning to deep learning as the core engine of deciphering the protein-DNA interaction and designing new strands of RNA-DNA.
This talk covers the following topics
- Primary Analysis
- Downstream or Secondary Analysis
- Genome-Wide Association Study (GWAS)
- Genetic Origami
- CRISPR-CAS9","Hossein Akhlaghpour has near two decades of experience leading enterprise scale software applications in the e-commerce, finance, and healthcare industries. He led development of entire software stack at Genapsys and played a played a key role in planning and management of the development of Genapsys DNA Sequencer. Prior to joining GenapSys, Hossein was a technical manager leading the development of one of the top three strategic products at Velti, an advertisement multi-channel tracking system that could handle 50 billion records per month and provided big data analytics to Velti’s partners. As a senior architect at eBay, Hossein was responsible for the development of an application that processed 200 million deals daily and integrated with more than 100 partners. The system used a cluster of in-house Hadoop-based servers and processed more than one Terabyte of data daily. In the past, Mr. Akhlaghpour has led teams of onsite/offshore developers and managed two multi-million dollar projects using agile and scrum methodology.

Hossein holds an MS in Solid State Physics from the University of Cincinnati, and a BS degree in Physics from Sharif University of Technology.",hossein-akhlaghpour.html,<div class='col-md-3'><div class='speaker'><a href='speakers/hossein-akhlaghpour.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/hossein-akhlaghpour.jpg' width='250px'></figure><h4>Hossein Akhlaghpour</h4><p></p></a></div></div>,"\newtalk{Hossein Akhlaghpour}{mahsa.mohammadikaji@kit.edu}{hossein-akhlaghpour.jpg}{}{Hossein Akhlaghpour has near two decades of experience leading enterprise scale software applications in the e-commerce, finance, and healthcare industries. He led development of entire software stack at Genapsys and played a played a key role in planning and management of the development of Genapsys DNA Sequencer. Prior to joining GenapSys, Hossein was a technical manager leading the development of one of the top three strategic products at Velti, an advertisement multi-channel tracking system that could handle 50 billion records per month and provided big data analytics to Velti’s partners. As a senior architect at eBay, Hossein was responsible for the development of an application that processed 200 million deals daily and integrated with more than 100 partners. The system used a cluster of in-house Hadoop-based servers and processed more than one Terabyte of data daily. In the past, Mr. Akhlaghpour has led teams of onsite/offshore developers and managed two multi-million dollar projects using agile and scrum methodology.

Hossein holds an MS in Solid State Physics from the University of Cincinnati, and a BS degree in Physics from Sharif University of Technology.}{How Deep Learning shapes the future of Bioinformatics}{In this talk we go over different aspects of Bioinformatics and show how Machine Learning and specifically Deep Learning will have such an impact that future Bioinformaticians are none but Computer Scientists specialized on Deep Learning.
We show how Google and Microsoft are the ones that not only lead bioinformatics but also can monopolize this industry.  What we call Bioinformatics today will be the blueprint of manufacturing of all kind of products from foods and drugs to batteries,  solar cells, industrial and construction materials. Such an explosion of applications are not possible without turning to deep learning as the core engine of deciphering the protein-DNA interaction and designing new strands of RNA-DNA.
This talk covers the following topics
- Primary Analysis
- Downstream or Secondary Analysis
- Genome-Wide Association Study (GWAS)
- Genetic Origami
- CRISPR-CAS9}{hossein-akhlaghpour.html}"
Mahsa Mohammadi Kaji,Karlsruhe Institute of Technology,mahsa.mohammadikaji@kit.edu,mahsa-mohammad-kaji.jpg,Automated Visual Inspection for Industrial Quality Assurance,"In the manufacturing process, an inspection is aimed at determining if a product deviates from a set of given specifications. Depending on the demands and the product features, different visual inspection techniques are typically applied in industry, including but not limited to, laser triangulation, fringe projection, and deflectometry. The inspection setups have often several degrees of freedom including the position and orientation of the cameras and the illuminations, as well as their optical configurations. A manual setup design for inspecting complicated products, such as an engine block, requires a tedious trial-and-error process, associated with high costs and often non-optimal results. This talk will give an overview of different visual techniques used for industrial 3D scanning, starting from the traditional stereo reconstruction to specific technical solutions. Moreover, I will introduce the “Inspection Planning” problem for optimizing the sequence of sensor acquisitions to best scan a product. To quantify an inspection quality, we formulate the amount of information an acquisition delivers, as a reduction of our uncertainty about the product surface, using a Bayesian framework. This is then used an optimization cost fuction for the planning problem.This talk will also cover topics regarding the physically-based computer graphics simulation of images, and methods for quantification of the measurement uncertainty in an optical measurement.","Mahsa Mohammadikaji is currently a 3rd-year PhD student at the Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany. Her PhD work is concentrated on applied computer vision for industrial inspection planning and product quality assurance.  She received her master degree in artificial intelligence in 2014, and her bachelor degree in software engineering in 2012, both from Sharif University of Technology.",mahsa-mohammadi-kaji.html,<div class='col-md-3'><div class='speaker'><a href='speakers/mahsa-mohammadi-kaji.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/mahsa-mohammad-kaji.jpg' width='250px'></figure><h4>Mahsa Mohammadi Kaji</h4><p>Karlsruhe Institute of Technology</p></a></div></div>,"\newtalk{Mahsa Mohammadi Kaji}{mahsa.mohammadikaji@kit.edu}{mahsa-mohammad-kaji.jpg}{Karlsruhe Institute of Technology}{Mahsa Mohammadikaji is currently a 3rd-year PhD student at the Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany. Her PhD work is concentrated on applied computer vision for industrial inspection planning and product quality assurance.  She received her master degree in artificial intelligence in 2014, and her bachelor degree in software engineering in 2012, both from Sharif University of Technology.}{Automated Visual Inspection for Industrial Quality Assurance}{In the manufacturing process, an inspection is aimed at determining if a product deviates from a set of given specifications. Depending on the demands and the product features, different visual inspection techniques are typically applied in industry, including but not limited to, laser triangulation, fringe projection, and deflectometry. The inspection setups have often several degrees of freedom including the position and orientation of the cameras and the illuminations, as well as their optical configurations. A manual setup design for inspecting complicated products, such as an engine block, requires a tedious trial-and-error process, associated with high costs and often non-optimal results. This talk will give an overview of different visual techniques used for industrial 3D scanning, starting from the traditional stereo reconstruction to specific technical solutions. Moreover, I will introduce the “Inspection Planning” problem for optimizing the sequence of sensor acquisitions to best scan a product. To quantify an inspection quality, we formulate the amount of information an acquisition delivers, as a reduction of our uncertainty about the product surface, using a Bayesian framework. This is then used an optimization cost fuction for the planning problem.This talk will also cover topics regarding the physically-based computer graphics simulation of images, and methods for quantification of the measurement uncertainty in an optical measurement.}{mahsa-mohammadi-kaji.html}"
Maryam Aliakbarpour,"PhD, Massachusetts Institute of Technology",maryama@mit.edu,maryam-aliakbarpour.jpg,The problem of relevant features in distributions: Learning and Testing Junta Distributions,"We consider the problem of learning distributions in the presence of irrelevant features. This problem is formalized by introducing a new notion of k-junta distributions. Informally, a distribution D over the domain X^n is a","She is a Ph.D. student at MIT, affiliated with the Theory of computation group at CSAIL. She is supervised by Ronitt Rubinfeld. Her research involves sublinear algorithms and property testing. In particular, she works on learning and testing of distributions. She studied as an undergraduate student in Computer Engineering at Sharif University of Technology.",maryam-aliakbarpour.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/maryam-aliakbarpour.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/maryam-aliakbarpour.jpg' width='250px'></figure><h4>Maryam Aliakbarpour</h4><p>PhD, Massachusetts Institute of Technology</p></a></div></div>","\newtalk{Maryam Aliakbarpour}{maryama@mit.edu}{maryam-aliakbarpour.jpg}{PhD, Massachusetts Institute of Technology}{She is a Ph.D. student at MIT, affiliated with the Theory of computation group at CSAIL. She is supervised by Ronitt Rubinfeld. Her research involves sublinear algorithms and property testing. In particular, she works on learning and testing of distributions. She studied as an undergraduate student in Computer Engineering at Sharif University of Technology.}{The problem of relevant features in distributions: Learning and Testing Junta Distributions}{We consider the problem of learning distributions in the presence of irrelevant features. This problem is formalized by introducing a new notion of k-junta distributions. Informally, a distribution D over the domain X^n is a}{maryam-aliakbarpour.html}"
Maryam Sharifzadeh,"PostDoc, University of Warwick",sharifz2@illinois.edu,maryam-sharifzadeh.jpg,Sparse robust expander,"One of the most exciting developments in combinatorics in the past four decades is that of expanders. It was first introduced to construct networks (represented by graphs) that are economical (sparse) and robust (highly connected). Depending on the perspective, expanders can be defined in various different ways. From the algebraic point of view, expanders are the graphs with large spectral gap; from the probabilistic point of view, random walks on expanders are rapidly mixing; and from the graph theoretic point of view, an expander is a graph whose vertex subsets have `large' boundaries. Due to this nature, expanders have found applications in other areas of mathematics and theoretical computer science. In this talk, I will present an embedding strategy using a notion of sublinear expander first introduced by Komlos and Szemeredi. As applications, it settles a conjecture of Mader in $1999$ on large clique-subdivisions in dense graphs without $4$-cycles. Joint work with Jozsef Balogh and Hong Liu.",I am a postdoctoral researcher at the Mathematics Institute of the University of Warwick with Oleg Pikhurko. I completed my PhD at the University of Illinois at Urbana-Champaign in August 2016 advised by J\'ozsef Balogh.,maryam-sharifzadeh.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/maryam-sharifzadeh.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/maryam-sharifzadeh.jpg' width='250px'></figure><h4>Maryam Sharifzadeh</h4><p>PostDoc, University of Warwick</p></a></div></div>","\newtalk{Maryam Sharifzadeh}{sharifz2@illinois.edu}{maryam-sharifzadeh.jpg}{PostDoc, University of Warwick}{I am a postdoctoral researcher at the Mathematics Institute of the University of Warwick with Oleg Pikhurko. I completed my PhD at the University of Illinois at Urbana-Champaign in August 2016 advised by J\'ozsef Balogh.}{Sparse robust expander}{One of the most exciting developments in combinatorics in the past four decades is that of expanders. It was first introduced to construct networks (represented by graphs) that are economical (sparse) and robust (highly connected). Depending on the perspective, expanders can be defined in various different ways. From the algebraic point of view, expanders are the graphs with large spectral gap; from the probabilistic point of view, random walks on expanders are rapidly mixing; and from the graph theoretic point of view, an expander is a graph whose vertex subsets have `large' boundaries. Due to this nature, expanders have found applications in other areas of mathematics and theoretical computer science. In this talk, I will present an embedding strategy using a notion of sublinear expander first introduced by Komlos and Szemeredi. As applications, it settles a conjecture of Mader in $1999$ on large clique-subdivisions in dense graphs without $4$-cycles. Joint work with Jozsef Balogh and Hong Liu.}{maryam-sharifzadeh.html}"
Mohammad Babaiezadeh,"PhD, University of Illinois at Urbana–Champaign",mb2@illinois.edu,mohammad-babaiezadeh.jpg,Deep Learning at Scale,"The extraordinary success of Deep Learning hinges on two important factors: first, increase in the availability of the data, and second, accessibility to more computation power. As data grows and computations become more complex, so does the infeasibility of producing deep learning models on a single machine.  The solution is to  scale out  to multiple  machines,  using the “power of many.” Currently, single machines equipped with multiple GPUs are the primary source of computational power.  However, there exist an operating point where a distributed implementation becomes a necessity due to limited memory and computation power of a single GPU. Training large networks on large image classification tasks currently takes multiple days or even weeks. In some other applications, such as the Deep Reinforcement, the current training time exceeds a week even for small networks. In this talk, I will go through the scalability issues of deep learning, current state-of-the-art, and the future research directions.","Mohammad Babaeizadeh [Sharif alumni (MS 2009)] is currently a Ph.D. student at Computer Science Department in University of Illinois at Urbana-Champaign. His primary research interest is large-scale machine learning and its applications. His current focus is scalability of training and inference of deep models. Before joining UIUC, he worked in machine learning oriented industries for several years, including Microsoft Cortana and Nvidia research.",mohammad-babaiezadeh.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/mohammad-babaiezadeh.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/mohammad-babaiezadeh.jpg' width='250px'></figure><h4>Mohammad Babaiezadeh</h4><p>PhD, University of Illinois at Urbana–Champaign</p></a></div></div>","\newtalk{Mohammad Babaiezadeh}{mb2@illinois.edu}{mohammad-babaiezadeh.jpg}{PhD, University of Illinois at Urbana–Champaign}{Mohammad Babaeizadeh [Sharif alumni (MS 2009)] is currently a Ph.D. student at Computer Science Department in University of Illinois at Urbana-Champaign. His primary research interest is large-scale machine learning and its applications. His current focus is scalability of training and inference of deep models. Before joining UIUC, he worked in machine learning oriented industries for several years, including Microsoft Cortana and Nvidia research.}{Deep Learning at Scale}{The extraordinary success of Deep Learning hinges on two important factors: first, increase in the availability of the data, and second, accessibility to more computation power. As data grows and computations become more complex, so does the infeasibility of producing deep learning models on a single machine.  The solution is to  scale out  to multiple  machines,  using the “power of many.” Currently, single machines equipped with multiple GPUs are the primary source of computational power.  However, there exist an operating point where a distributed implementation becomes a necessity due to limited memory and computation power of a single GPU. Training large networks on large image classification tasks currently takes multiple days or even weeks. In some other applications, such as the Deep Reinforcement, the current training time exceeds a week even for small networks. In this talk, I will go through the scalability issues of deep learning, current state-of-the-art, and the future research directions.}{mohammad-babaiezadeh.html}"
Mohammad Dashti,"PhD, École Polytechnique Fédérale de Lausanne",mohammad.dashti@epfl.ch,mohammad-dashti.jpg,Repairing Transaction Conflicts in Optimistic Multi-Version Concurrency Control,"The optimistic variants of Multi-Version Concurrency Control (MVCC) avoid blocking concurrent transactions at the cost of having a validation phase. Upon failure in the validation phase, the transaction is usually aborted and restarted from scratch. The “abort and restart” approach becomes a performance bottleneck for use cases with high contention objects or long running transactions. In addition, restarting from scratch creates a negative feedback loop in the system, because the system incurs additional overhead that may create even more conflicts. In this paper, we propose a novel approach for conflict resolution in MVCC for in-memory databases. This low overhead approach summarizes the transaction programs in the form of a dependency graph. The dependency graph also contains the constructs used in the validation phase of the MVCC algorithm. Then, when encountering conflicts among transactions, our mechanism quickly detects the conflict locations in the program and partially re-executes the conflicting transactions. This approach maximizes the reuse of the computations done in the initial execution round, and increases the transaction processing throughput.","Mohammad is a 5th-year PhD student at EPFL in Switzerland, advised by Prof. Christoph Koch. He is interested in database systems (in particular, transaction processing) and programming languages (in particular, compilation techniques). In his PhD research, he is pushing the limits of achieving high throughput/low latency for transaction processing while keeping the state strongly consistent, mainly by applying compilation techniques. Mentored by Phil Bernstein, he also did an internship at Microsoft Research in Redmond on Microsoft Orleans project  and is currently an open-source contributor to this project.",mohammad-dashti.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/mohammad-dashti.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/mohammad-dashti.jpg' width='250px'></figure><h4>Mohammad Dashti</h4><p>PhD, École Polytechnique Fédérale de Lausanne</p></a></div></div>","\newtalk{Mohammad Dashti}{mohammad.dashti@epfl.ch}{mohammad-dashti.jpg}{PhD, École Polytechnique Fédérale de Lausanne}{Mohammad is a 5th-year PhD student at EPFL in Switzerland, advised by Prof. Christoph Koch. He is interested in database systems (in particular, transaction processing) and programming languages (in particular, compilation techniques). In his PhD research, he is pushing the limits of achieving high throughput/low latency for transaction processing while keeping the state strongly consistent, mainly by applying compilation techniques. Mentored by Phil Bernstein, he also did an internship at Microsoft Research in Redmond on Microsoft Orleans project  and is currently an open-source contributor to this project.}{Repairing Transaction Conflicts in Optimistic Multi-Version Concurrency Control}{The optimistic variants of Multi-Version Concurrency Control (MVCC) avoid blocking concurrent transactions at the cost of having a validation phase. Upon failure in the validation phase, the transaction is usually aborted and restarted from scratch. The “abort and restart” approach becomes a performance bottleneck for use cases with high contention objects or long running transactions. In addition, restarting from scratch creates a negative feedback loop in the system, because the system incurs additional overhead that may create even more conflicts. In this paper, we propose a novel approach for conflict resolution in MVCC for in-memory databases. This low overhead approach summarizes the transaction programs in the form of a dependency graph. The dependency graph also contains the constructs used in the validation phase of the MVCC algorithm. Then, when encountering conflicts among transactions, our mechanism quickly detects the conflict locations in the program and partially re-executes the conflicting transactions. This approach maximizes the reuse of the computations done in the initial execution round, and increases the transaction processing throughput.}{mohammad-dashti.html}"
Mohammad Javad Faraji,"PhD, École Polytechnique Fédérale de Lausanne",mohammadjavad.faraji@epfl.ch,mohammad-javad-faraji.jpg,Synaptic Plasticity Rules: Neural Substrates of Learning,"One of the most significant characteristics of our brain is the ability of quick learning and adaptation. In order to unravel the mysteries behind learning, we need to have a strong theoretical framework that explains how a network of neurons can efficiently process huge amount of information. In this talk, I will focus on theoretical cornerstone of synaptic plasticity rules that can be used to describe behavioral properties of memory formation and action learning in the brain. I will describe two general classes of (Hebbian and neo-Hebbian) learning rules, and demonstrate how they can be used for general paradigms of learning in unsupervised and reinforcement-based fashion, respectively. I will specifically focus on models of plasticity that are under the influence of global factors (such as reward or surprise) which can represent the action of one or several neuromodulators, attentional control, or feedback from large populations of neurons.","Mohammadjavad Faraji obtained his B.Sc. in Electrical Engineering at Sharif University of Technology, Tehran, Iran in 2009. He completed his M.Sc. in Communication Systems at Ecole Polytechnique Federal de Lausanne (EPFL) in 2011. He finished his Ph.D. in Computer Science with a specialization in Computational Neuroscience in 2016 at EPFL, under the supervision of Prof. Wulfram Gerstner. During his doctoral study, he has worked on the computational modeling of novelty and surprise signals and how they affect learning in machines (particularly, the brain). His research interests include computational neuroscience, statistical machine learning, and signal processing.",mohammad-javad-faraji.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/mohammad-javad-faraji.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/mohammad-javad-faraji.jpg' width='250px'></figure><h4>Mohammad Javad Faraji</h4><p>PhD, École Polytechnique Fédérale de Lausanne</p></a></div></div>","\newtalk{Mohammad Javad Faraji}{mohammadjavad.faraji@epfl.ch}{mohammad-javad-faraji.jpg}{PhD, École Polytechnique Fédérale de Lausanne}{Mohammadjavad Faraji obtained his B.Sc. in Electrical Engineering at Sharif University of Technology, Tehran, Iran in 2009. He completed his M.Sc. in Communication Systems at Ecole Polytechnique Federal de Lausanne (EPFL) in 2011. He finished his Ph.D. in Computer Science with a specialization in Computational Neuroscience in 2016 at EPFL, under the supervision of Prof. Wulfram Gerstner. During his doctoral study, he has worked on the computational modeling of novelty and surprise signals and how they affect learning in machines (particularly, the brain). His research interests include computational neuroscience, statistical machine learning, and signal processing.}{Synaptic Plasticity Rules: Neural Substrates of Learning}{One of the most significant characteristics of our brain is the ability of quick learning and adaptation. In order to unravel the mysteries behind learning, we need to have a strong theoretical framework that explains how a network of neurons can efficiently process huge amount of information. In this talk, I will focus on theoretical cornerstone of synaptic plasticity rules that can be used to describe behavioral properties of memory formation and action learning in the brain. I will describe two general classes of (Hebbian and neo-Hebbian) learning rules, and demonstrate how they can be used for general paradigms of learning in unsupervised and reinforcement-based fashion, respectively. I will specifically focus on models of plasticity that are under the influence of global factors (such as reward or surprise) which can represent the action of one or several neuromodulators, attentional control, or feedback from large populations of neurons.}{mohammad-javad-faraji.html}"
Mohammad Mahmoudi,"Assistant Professor, University of Virginia",mohammad@cs.virginia.edu,mohammad-mahmoudi.jpg,Code Obfuscation from Encryption?,"Code obfuscation can be seen as ""encrypting"" a ""program"" in a way that allows us to run it, while keeping its implementation as hidden as possible. So it is natural to ask whether code obfuscation could be based on very strong recently developed forms of encryption such as: witness encryption, predicate encryption, or functional encryption. In this talk, I will describe what these primitives are, and then I will describe a set of positive and negative results that give almost a full picture for the question above.",Mohammad Mahmoody finished his undergraduate studies at the computer science department of Sharif University in 2004. He then joined Princeton university for his PhD studies where he worked on foundations of cryptography. He then joined Cornell university for his post-doctoral studies and since 2013 he is an assistant professor at the University of Virginia.,mohammad-mahmoudi.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/mohammad-mahmoudi.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/mohammad-mahmoudi.jpg' width='250px'></figure><h4>Mohammad Mahmoudi</h4><p>Assistant Professor, University of Virginia</p></a></div></div>","\newtalk{Mohammad Mahmoudi}{mohammad@cs.virginia.edu}{mohammad-mahmoudi.jpg}{Assistant Professor, University of Virginia}{Mohammad Mahmoody finished his undergraduate studies at the computer science department of Sharif University in 2004. He then joined Princeton university for his PhD studies where he worked on foundations of cryptography. He then joined Cornell university for his post-doctoral studies and since 2013 he is an assistant professor at the University of Virginia.}{Code Obfuscation from Encryption?}{Code obfuscation can be seen as ""encrypting"" a ""program"" in a way that allows us to run it, while keeping its implementation as hidden as possible. So it is natural to ask whether code obfuscation could be based on very strong recently developed forms of encryption such as: witness encryption, predicate encryption, or functional encryption. In this talk, I will describe what these primitives are, and then I will describe a set of positive and negative results that give almost a full picture for the question above.}{mohammad-mahmoudi.html}"
Mohsen Mousavi Dezfouli,"PhD, École Polytechnique Fédérale de Lausanne",seyed.moosavi@epfl.ch,mohsen-mousavi-dezfouli.jpg,Robustness of Image Classifiers,"In this talk, we will present tools to assess the robustness of image classifiers to a diverse set of perturbations, ranging from adversarial to random noise. In particular, we will propose a semi-random noise regime that generalizes both the random and adversarial noise regimes. We provide theoretical bounds on the robustness of classifiers in this general regime, which depends on the curvature of the classifier's decision boundary. In a final part of the talk, we will show how it can explain the surprising existence of universal perturbation images that cause most natural images to be misclassified by state-of-the-art deep neural network classifiers.","Seyed Mohsen Moosavi is a PhD student in the school of Communication and Computer Sciences at EPFL. Prior to that, he received his B.Sc. in Electrical Engineering from Amirkabir University of Technology (Tehran Polytechnic) and his M.Sc. in Communication Systems from EPFL in 2012 and 2014 respectively. During his master’s studies, he worked on random tomography as a research assistant under the supervision of Prof. Martin Vetterli. He then stayed at ABB Corporate Research Center for six months. He started his PhD in September 2014 and he is currently working on the robustness of deep neural networks at Signal Processing Laboratory 4 under the supervision of Prof. Pascal Frossard.",mohsen-mousavi-dezfouli.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/mohsen-mousavi-dezfouli.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/mohsen-mousavi-dezfouli.jpg' width='250px'></figure><h4>Mohsen Mousavi Dezfouli</h4><p>PhD, École Polytechnique Fédérale de Lausanne</p></a></div></div>","\newtalk{Mohsen Mousavi Dezfouli}{seyed.moosavi@epfl.ch}{mohsen-mousavi-dezfouli.jpg}{PhD, École Polytechnique Fédérale de Lausanne}{Seyed Mohsen Moosavi is a PhD student in the school of Communication and Computer Sciences at EPFL. Prior to that, he received his B.Sc. in Electrical Engineering from Amirkabir University of Technology (Tehran Polytechnic) and his M.Sc. in Communication Systems from EPFL in 2012 and 2014 respectively. During his master’s studies, he worked on random tomography as a research assistant under the supervision of Prof. Martin Vetterli. He then stayed at ABB Corporate Research Center for six months. He started his PhD in September 2014 and he is currently working on the robustness of deep neural networks at Signal Processing Laboratory 4 under the supervision of Prof. Pascal Frossard.}{Robustness of Image Classifiers}{In this talk, we will present tools to assess the robustness of image classifiers to a diverse set of perturbations, ranging from adversarial to random noise. In particular, we will propose a semi-random noise regime that generalizes both the random and adversarial noise regimes. We provide theoretical bounds on the robustness of classifiers in this general regime, which depends on the curvature of the classifier's decision boundary. In a final part of the talk, we will show how it can explain the surprising existence of universal perturbation images that cause most natural images to be misclassified by state-of-the-art deep neural network classifiers.}{mohsen-mousavi-dezfouli.html}"
Naeimeh Omidvar,"PhD, Hong Kong University of Science and Technology",nomidvar@ust.hk,naeimeh-omidvar.jpg,Online Stochastic Optimisation for Large-Scale Machine Learning Problems in Big Data,"Support vector machine (SVM) is considered as the standard technique for a wide range of data classification problems in many different fields, such as cancer diagnostic in bioinformatics, image classification, face recognition in computer vision and text categorisation in document processing. However, in a big data environment, computing the SVM classifier amounts to solve a large-scale optimisation which is mathematically complex and computationally expensive and the existing optimisation methods would not be fast enough. The main objective of this talk is to propose an accelerated stochastic optimisation method to solve SVMs for big data applications, which benefits from fast convergence, low complexity and easy implementation. The convergence analysis of the new method is theoretically investigated and also using some real-world data sets, the proposed algorithm is compared to the existing state of the art algorithms. Numerical results show that the proposed method significantly outperforms the existing schemes with orders of magnitude higher convergence rate.","Naeimeh Omidvar received her B.Sc. and M.Sc. both in Communication Systems Engineering from Sharif University of Technology, Tehran, Iran, in 2009 and 2011, respectively. She is currently pursuing her Ph.D. studies in the Hong Kong University of Science and Technology and Sharif University of Technology, under a double-degree Ph.D. program. Her research interests include multi-timescale stochastic optimisations, large-scale optimisation for big data, green networking, data networking algorithms and protocols, cross-layer radio resource management for future networks, and game theory. She is also involved in various industrial projects at Huawei-HKUST Joint Innovation Lab at HKUST, Hong Kong.",naeimeh-omidvar.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/naeimeh-omidvar.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/naeimeh-omidvar.jpg' width='250px'></figure><h4>Naeimeh Omidvar</h4><p>PhD, Hong Kong University of Science and Technology</p></a></div></div>","\newtalk{Naeimeh Omidvar}{nomidvar@ust.hk}{naeimeh-omidvar.jpg}{PhD, Hong Kong University of Science and Technology}{Naeimeh Omidvar received her B.Sc. and M.Sc. both in Communication Systems Engineering from Sharif University of Technology, Tehran, Iran, in 2009 and 2011, respectively. She is currently pursuing her Ph.D. studies in the Hong Kong University of Science and Technology and Sharif University of Technology, under a double-degree Ph.D. program. Her research interests include multi-timescale stochastic optimisations, large-scale optimisation for big data, green networking, data networking algorithms and protocols, cross-layer radio resource management for future networks, and game theory. She is also involved in various industrial projects at Huawei-HKUST Joint Innovation Lab at HKUST, Hong Kong.}{Online Stochastic Optimisation for Large-Scale Machine Learning Problems in Big Data}{Support vector machine (SVM) is considered as the standard technique for a wide range of data classification problems in many different fields, such as cancer diagnostic in bioinformatics, image classification, face recognition in computer vision and text categorisation in document processing. However, in a big data environment, computing the SVM classifier amounts to solve a large-scale optimisation which is mathematically complex and computationally expensive and the existing optimisation methods would not be fast enough. The main objective of this talk is to propose an accelerated stochastic optimisation method to solve SVMs for big data applications, which benefits from fast convergence, low complexity and easy implementation. The convergence analysis of the new method is theoretically investigated and also using some real-world data sets, the proposed algorithm is compared to the existing state of the art algorithms. Numerical results show that the proposed method significantly outperforms the existing schemes with orders of magnitude higher convergence rate.}{naeimeh-omidvar.html}"
Narges Shahidi,"PhD, Pennsylvania State University",nshahidi@alum.sharif.edu,narges-shahidi.jpg,Parallel Garbage collection in Solid State Drives,"In the last decade NAND Flash-based SSDs have been widely adopted for high-end enterprise systems in an attempt to provide a high-performance and reliable storage. However, inferior performance is frequently attained mainly due to need for Garbage Collection (GC). GC in flash memory is the process of identifying and clearing the blocks of unneeded data to create space for the new data to be allocated. GC is high-latency operation and once it is scheduled it can increase latency for later arriving I/O requests. On the other hands, SSDs have high levels of parallelism provided by channels, chips, dies and planes, which is sometimes under-utilized due to the resource contention. In this work, we propose a novel GC strategy, which leverages plane-level parallelism to improve GC latency and reduce performance inconsistencies. ","Narges Shahidi received her B.Sc and M.Sc from Computer Engineering department at Sharif University of Technology at 2008, and 2010 respectively. She is currently a PhD student at Pennsylvania State University. Her research is focused on NAND Flash Solid State Drives. During her PhD she interned at several academic and industry labs, including Camel Lab at University of Texas at Dallas, Memory Solution Lab at Samsung Semiconductor Inc. (SSI) and Google Inc.",narges-shahidi.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/narges-shahidi.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/narges-shahidi.jpg' width='250px'></figure><h4>Narges Shahidi</h4><p>PhD, Pennsylvania State University</p></a></div></div>","\newtalk{Narges Shahidi}{nshahidi@alum.sharif.edu}{narges-shahidi.jpg}{PhD, Pennsylvania State University}{Narges Shahidi received her B.Sc and M.Sc from Computer Engineering department at Sharif University of Technology at 2008, and 2010 respectively. She is currently a PhD student at Pennsylvania State University. Her research is focused on NAND Flash Solid State Drives. During her PhD she interned at several academic and industry labs, including Camel Lab at University of Texas at Dallas, Memory Solution Lab at Samsung Semiconductor Inc. (SSI) and Google Inc.}{Parallel Garbage collection in Solid State Drives}{In the last decade NAND Flash-based SSDs have been widely adopted for high-end enterprise systems in an attempt to provide a high-performance and reliable storage. However, inferior performance is frequently attained mainly due to need for Garbage Collection (GC). GC in flash memory is the process of identifying and clearing the blocks of unneeded data to create space for the new data to be allocated. GC is high-latency operation and once it is scheduled it can increase latency for later arriving I/O requests. On the other hands, SSDs have high levels of parallelism provided by channels, chips, dies and planes, which is sometimes under-utilized due to the resource contention. In this work, we propose a novel GC strategy, which leverages plane-level parallelism to improve GC latency and reduce performance inconsistencies. }{narges-shahidi.html}"
Nooshin Mirzadeh,"PhD, École Polytechnique Fédérale de Lausanne",nooshin.mirzadeh@epfl.ch,nooshin-mirzadeh.jpg,The Mondrian Data Engine: Unleashing the Vast Internal Bandwidth of Near-Memory Architectures for Data Analytics,"The increasing demand for extracting value out of ever-growing data poses an ongoing challenge to system designers, a task only made trickier by the end of Dennard scaling. As the performance density of traditional CPU-centric architectures stagnates, advancing compute capabilities necessitates novel highly efficient architectures. Near-memory processing (NMP) architectures are reemerging as a promising approach to improve computing efficiency through tight coupling of logic and memory. NMP architectures are a great fit for data analytics, as they provide immense bandwidth to memory-resident data and dramatically reduce data movement, the main source of energy consumption. While moving from CPU-centric to NMP architectures alone boosts the performance of data analytics, maximizing NMP efficiency in terms of performance/watt is not equally straightforward. CPU-optimized data analytics operators rely on random memory access, which, in the context of NMP, result in wasteful DRAM row buffer activations. In addition, sustaining high enough memory-level parallelism to utilize NMP's ample bandwidth with fine-grained accesses requires non-trivial hardware, that cannot be accommodated under NMP's tight area and power constraints. We argue that efficient NMP calls for an algorithm-hardware co-design that favors algorithms with sequential accesses to enable simple hardware that accesses memory in streams. We then introduce the Mondrian Data Engine, an NMP architecture for data analytics that strikes that sweet spot.","Nooshin Mirzadeh is a student at Computer Sciences, École Polytechnique Fédérale de Lausanne (EPFL). She has been working in the Parallel Systems Architecture (PARSA) group, which advised by Prof. Babak Falsafi, since Sept. 2013. Her research interest lies in computer architecture, especially in high performance energy-efficient memory systems including 3D integration, and near-memory processing.",nooshin-mirzadeh.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/nooshin-mirzadeh.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/nooshin-mirzadeh.jpg' width='250px'></figure><h4>Nooshin Mirzadeh</h4><p>PhD, École Polytechnique Fédérale de Lausanne</p></a></div></div>","\newtalk{Nooshin Mirzadeh}{nooshin.mirzadeh@epfl.ch}{nooshin-mirzadeh.jpg}{PhD, École Polytechnique Fédérale de Lausanne}{Nooshin Mirzadeh is a student at Computer Sciences, École Polytechnique Fédérale de Lausanne (EPFL). She has been working in the Parallel Systems Architecture (PARSA) group, which advised by Prof. Babak Falsafi, since Sept. 2013. Her research interest lies in computer architecture, especially in high performance energy-efficient memory systems including 3D integration, and near-memory processing.}{The Mondrian Data Engine: Unleashing the Vast Internal Bandwidth of Near-Memory Architectures for Data Analytics}{The increasing demand for extracting value out of ever-growing data poses an ongoing challenge to system designers, a task only made trickier by the end of Dennard scaling. As the performance density of traditional CPU-centric architectures stagnates, advancing compute capabilities necessitates novel highly efficient architectures. Near-memory processing (NMP) architectures are reemerging as a promising approach to improve computing efficiency through tight coupling of logic and memory. NMP architectures are a great fit for data analytics, as they provide immense bandwidth to memory-resident data and dramatically reduce data movement, the main source of energy consumption. While moving from CPU-centric to NMP architectures alone boosts the performance of data analytics, maximizing NMP efficiency in terms of performance/watt is not equally straightforward. CPU-optimized data analytics operators rely on random memory access, which, in the context of NMP, result in wasteful DRAM row buffer activations. In addition, sustaining high enough memory-level parallelism to utilize NMP's ample bandwidth with fine-grained accesses requires non-trivial hardware, that cannot be accommodated under NMP's tight area and power constraints. We argue that efficient NMP calls for an algorithm-hardware co-design that favors algorithms with sequential accesses to enable simple hardware that accesses memory in streams. We then introduce the Mondrian Data Engine, an NMP architecture for data analytics that strikes that sweet spot.}{nooshin-mirzadeh.html}"
Shayan Bordbar,"PhD, University of Illinois at Urbana–Champaign",tabebor2@illinois.edu,shayan-bordbar.jpg,Applying Sequence to expression modeling to experiment design and analysis,"DNA sequence consists of coding and non-coding region. Coding regions are transcribed to mRNA and later translated to proteins, but the role of non-coding region which forms nearly 98% of the total DNA is not clear. Parts of non-coding region that contain binding sites for proteins called transcription factors (TFs) are known as enhancers. Enhancers are known to regulate the expression of nearby genes. We use Thermodynamic models to explain the expression of one gene based on the sequence of its enhancer, the relative concentration of its relevant TFs and known binding sites for each TF. Modeling approach leads to an ensemble of models in agreement with current data. In order to constrain the ensemble, we choose variants that distinguish our models the most and test them experimentally using massively parallel reporter assays. Refining the models using the experimental results helps us to unravel the complex regulatory network governing the expression of gene of interest.",I earned my Bachelors and Masters in biotechnology at university of Tehran (2007-2013). I continued my education at university of Illinois in the field of computational neuroscience and earned a master’s degree in molecular and integrative physiology (2013-2015). Afterwards I started my current program in bioinformatics computer science department and University of Illinois in professor Sinha’s group.,shayan-bordbar.html,"<div class='col-md-3'><div class='speaker'><a href='speakers/shayan-bordbar.html'><figure><img alt='' class='img-responsive center-block' src='assets/images/speakers/shayan-bordbar.jpg' width='250px'></figure><h4>Shayan Bordbar</h4><p>PhD, University of Illinois at Urbana–Champaign</p></a></div></div>","\newtalk{Shayan Bordbar}{tabebor2@illinois.edu}{shayan-bordbar.jpg}{PhD, University of Illinois at Urbana–Champaign}{I earned my Bachelors and Masters in biotechnology at university of Tehran (2007-2013). I continued my education at university of Illinois in the field of computational neuroscience and earned a master’s degree in molecular and integrative physiology (2013-2015). Afterwards I started my current program in bioinformatics computer science department and University of Illinois in professor Sinha’s group.}{Applying Sequence to expression modeling to experiment design and analysis}{DNA sequence consists of coding and non-coding region. Coding regions are transcribed to mRNA and later translated to proteins, but the role of non-coding region which forms nearly 98% of the total DNA is not clear. Parts of non-coding region that contain binding sites for proteins called transcription factors (TFs) are known as enhancers. Enhancers are known to regulate the expression of nearby genes. We use Thermodynamic models to explain the expression of one gene based on the sequence of its enhancer, the relative concentration of its relevant TFs and known binding sites for each TF. Modeling approach leads to an ensemble of models in agreement with current data. In order to constrain the ensemble, we choose variants that distinguish our models the most and test them experimentally using massively parallel reporter assays. Refining the models using the experimental results helps us to unravel the complex regulatory network governing the expression of gene of interest.}{shayan-bordbar.html}"